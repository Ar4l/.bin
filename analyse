#!/usr/bin/env python3

############################################################
# If you want to use this script, just call `./analyse` 
# from the command line, it will help you further.
# Or, add it to your path and call `analyse` from anywhere.
############################################################

import os, sys, subprocess, json, datetime 
from dataclasses import dataclass 

# @dataclass
# class Data:

#     def read_metadata(self):
#         '''read in as pickle'''
#         if os.path.exists(self.METADATA_FILE):
#             with open(self.METADATA_FILE, 'rb') as f:
#                 return pickle.load(f)
#         else:
#             print('No metadata file found. Creating new one.')
#             self.save_metadata()
#             return self

#     def save_metadata(self):
#         '''save as pickle'''
#         with open(self.METADATA_FILE, 'wb') as f:
#             pickle.dump(self, f)
        
DATA_DIR = './data/'

class Analyse: # Functions in this class are exposed to CLI
    '''
    Utility for analysing code4me data
    '''
    def __init__(self):
        pass

    def _loop_over_data(self, func, start_index:int=0) -> list:
        '''
        Calls func on each data file, and returns a list of files that threw errors
        '''
        start_index = int(start_index) # somehow this is necessary (don't ask me why...)
        print(f'calling {func.__name__} on each file in {DATA_DIR} (starting at index {start_index})')

        data_iter = os.listdir(DATA_DIR)[start_index:]
        n_files = len(data_iter)
        print_step = n_files // 1000
        error_files = []

        for index, file in enumerate(data_iter):
            try: 
                func(file)
            except KeyboardInterrupt:
                print(f'\nStopped at index {index+start_index}')
                break
            except: 
                error_files.append(file)
                print(f'\tError on file {file} at index {index+start_index}')

            if index % print_step == 0:
                print(f'\r{index+1}/{n_files} ({100*(index+1)/n_files:.1f}%) {"remaining" if start_index != 0 else ""} files processed', end='')

        print(f'{len(error_files)} files threw errors and were not processed.')
        return error_files

    def sort_by_user(self, start_index:int = 0): # This should allow for faster file browsing and searching.
        '''
        Create a directory for each user, and store their queries in there.
        '''
        SORTED_DIR = 'sorted by users/'
        os.makedirs(SORTED_DIR, exist_ok=True)

        def move_to_user_dir(file):
            # create a copy of the file in the new directory
            user, new_file = file.rsplit('-', 1)
            os.makedirs(f'{SORTED_DIR}{user}', exist_ok=True)
            subprocess.run(['cp', f'{DATA_DIR}{file}', f'{SORTED_DIR}{user}/{new_file}'])

        error_files = self._loop_over_data(move_to_user_dir, start_index)

    def get_number_of_contexts(self):
        '''
        Returns the number of contexts in the data
        '''
        print('lol no')
        pass

if __name__ == '__main__':

    if len(sys.argv) > 1:
        analyse = Analyse()
        func = getattr(analyse, sys.argv[1])
        func(*sys.argv[2:])


    else:
        # print docstring of class without indentation
        print(Analyse.__doc__.strip())
        
        # print each function in class together with its docstring
        for name, func in Analyse.__dict__.items():
            if callable(func) and not name.startswith('_'):
                # print ITALICISED function name and doc in nice table
                print(f'\033[3m{name}\033[0m\t{func.__doc__.strip()}')